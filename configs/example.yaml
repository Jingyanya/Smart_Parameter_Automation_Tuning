docker:  
  host: 10.67.81.155  
  user: pvteam64
  password: atitech
  docker_path: "/home/amd/:/home/amd/"  
  docker_name: "vllm-cuda-0.6.4.post1:v1"  
  exe_path: "/app/vllm/"  

model:
  name: ["microsoft/Phi-3.5-vision-instruct"]
  dtype: ["float16"]
  block_size: [16]
  nccl_p2p_disable: [0, 1]
  max_num_seqs: [8]
  max_num_batched_tokens: [128]
  gpu_memory_util: [0.95]
  gpu: ["0,1,2,3,4,5,6,7"]
  max_model_len: [4096]
  tensor_parallel: [1]

  

benchmark:  
  dataset_name: sharegpt
  dataset_path: ["/app/data/sharegpt_gpt4_vicuna_format.json"]
  request_rate: [4, 8]
  num_prompts: [100, 1000]
  num_runs: 2

output_dir: "./result"